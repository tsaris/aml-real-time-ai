{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import amlrealtimeai\n",
    "from amlrealtimeai import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imghdr\n",
    "datadir = os.path.expanduser(\"/Users/atsaris/mygit_repos/ml_service/datasets\")\n",
    "\n",
    "cat_files = glob.glob(os.path.join(datadir, 'PetImages', 'Cat', '*.jpg'))\n",
    "dog_files = glob.glob(os.path.join(datadir, 'PetImages', 'Dog', '*.jpg'))\n",
    "\n",
    "# Limit the data set to make the notebook execute quickly.\n",
    "cat_files = cat_files[:64]\n",
    "dog_files = dog_files[:64]\n",
    "\n",
    "# The data set has a few images that are not jpeg. Remove them.\n",
    "cat_files = [f for f in cat_files if imghdr.what(f) == 'jpeg']\n",
    "dog_files = [f for f in dog_files if imghdr.what(f) == 'jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constructing a numpy array as labels\n",
    "image_paths = cat_files + dog_files\n",
    "total_files = len(cat_files) + len(dog_files)\n",
    "labels = np.zeros(total_files)\n",
    "labels[len(cat_files):] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Input images as a two-dimensional tensor containing an arbitrary number of images represented a strings\n",
    "import amlrealtimeai.resnet50.utils\n",
    "in_images = tf.placeholder(tf.string)\n",
    "image_tensors = resnet50.utils.preprocess_array(in_images)\n",
    "print(image_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code E3HT8PL27 to authenticate.\n",
      "1.1.6-rc\n"
     ]
    }
   ],
   "source": [
    "subscription_id = \"80defacd-509e-410c-9812-6e52ed6a0016\"\n",
    "resource_group = \"CMS_FPGA_Resources\"\n",
    "model_management_account = \"CMS_FPGA_1\"\n",
    "\n",
    "from amlrealtimeai.resnet50.model import RemoteQuantizedResNet50\n",
    "model_path = os.path.expanduser('~/models')\n",
    "featurizer = RemoteQuantizedResNet50(subscription_id, resource_group, model_management_account, model_path)\n",
    "print(featurizer.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model resnet50-1.1.6-rc-model\n",
      "Successfully registered model resnet50-1.1.6-rc-model\n",
      "Creating service featurizer-service-08cdb9\n",
      ". . . . . . . \n",
      "Successfully created service featurizer-service-08cdb9\n"
     ]
    }
   ],
   "source": [
    "featurizer.import_graph_def(include_top=False, input_tensor=image_tensors)\n",
    "features = featurizer.featurizer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:13,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1, 1, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def read_files(files):\n",
    "    contents = []\n",
    "    for path in files:\n",
    "        with open(path, 'rb') as f:\n",
    "            contents.append(f.read())\n",
    "    return contents\n",
    "        \n",
    "feature_list = []\n",
    "with tf.Session() as sess:\n",
    "    for chunk in tqdm(chunks(image_paths, 5)):\n",
    "        contents = read_files(chunk)\n",
    "        result = sess.run([features], feed_dict={in_images: contents})\n",
    "        feature_list.extend(result[0])\n",
    "\n",
    "feature_results = np.array(feature_list)\n",
    "print(feature_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "FC_SIZE = 1024\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape=(1, 1, 2048,)))\n",
    "model.add(Dense(FC_SIZE, activation='relu', input_dim=(1, 1, 2048,)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid', input_dim=FC_SIZE))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4,momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 1, 1, 2048) (32, 1, 1, 2048) (96, 2) (32, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "onehot_labels = np.array([[0,1] if i else [1,0] for i in labels])\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_results, onehot_labels, random_state=42, shuffle=True)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7973 - acc: 0.5469\n",
      "Epoch 2/16\n",
      "96/96 [==============================] - 0s 348us/step - loss: 0.8021 - acc: 0.5260\n",
      "Epoch 3/16\n",
      "96/96 [==============================] - 0s 400us/step - loss: 0.7748 - acc: 0.5521\n",
      "Epoch 4/16\n",
      "96/96 [==============================] - 0s 372us/step - loss: 0.7173 - acc: 0.5625\n",
      "Epoch 5/16\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.7384 - acc: 0.5469\n",
      "Epoch 6/16\n",
      "96/96 [==============================] - 0s 372us/step - loss: 0.7059 - acc: 0.6354\n",
      "Epoch 7/16\n",
      "96/96 [==============================] - 0s 382us/step - loss: 0.6052 - acc: 0.6979\n",
      "Epoch 8/16\n",
      "96/96 [==============================] - 0s 355us/step - loss: 0.6177 - acc: 0.6771\n",
      "Epoch 9/16\n",
      "96/96 [==============================] - 0s 382us/step - loss: 0.5627 - acc: 0.7188\n",
      "Epoch 10/16\n",
      "96/96 [==============================] - 0s 341us/step - loss: 0.5484 - acc: 0.7656\n",
      "Epoch 11/16\n",
      "96/96 [==============================] - 0s 371us/step - loss: 0.5147 - acc: 0.7604\n",
      "Epoch 12/16\n",
      "96/96 [==============================] - 0s 402us/step - loss: 0.4947 - acc: 0.8438\n",
      "Epoch 13/16\n",
      "96/96 [==============================] - 0s 369us/step - loss: 0.4507 - acc: 0.8281\n",
      "Epoch 14/16\n",
      "96/96 [==============================] - 0s 411us/step - loss: 0.4475 - acc: 0.8021\n",
      "Epoch 15/16\n",
      "96/96 [==============================] - 0s 412us/step - loss: 0.4246 - acc: 0.8438\n",
      "Epoch 16/16\n",
      "96/96 [==============================] - 0s 399us/step - loss: 0.3897 - acc: 0.9010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27a88400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=16, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0]\n",
      "[0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "y_probs = model.predict(X_test)\n",
    "y_prob_max = np.argmax(y_probs, 1)\n",
    "y_test_max = np.argmax(y_test, 1)\n",
    "print(y_prob_max)\n",
    "print(y_test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.875\n",
      "Precision 0.8235294117647058\n",
      "Recall 0.9333333333333333\n",
      "F1 0.8749999999999999\n",
      "AUC 0.04313725490196079\n",
      "Confusion Matrix [[14, 3], [1, 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import itertools\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# compute a bunch of classification metrics \n",
    "def classification_metrics(y_true, y_pred, y_prob):\n",
    "    cm_dict = {}\n",
    "    cm_dict['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    cm_dict['Precision'] =  precision_score(y_true, y_pred)\n",
    "    cm_dict['Recall'] =  recall_score(y_true, y_pred)\n",
    "    cm_dict['F1'] =  f1_score(y_true, y_pred) \n",
    "    cm_dict['AUC'] = roc_auc_score(y_true, y_prob[:,0])\n",
    "    cm_dict['Confusion Matrix'] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return cm_dict\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots a confusion matrix.\n",
    "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    New BSD License - see appendix\n",
    "    \"\"\"\n",
    "    cm_max = cm.max()\n",
    "    cm_min = cm.min()\n",
    "    if cm_min > 0: cm_min = 0\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_max = 1\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm_max / 2.\n",
    "    plt.clim(cm_min, cm_max)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\n",
    "                 round(cm[i, j], 3),  # round to 3 decimals if they are float\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "cm_dict = classification_metrics(y_test_max, y_prob_max, y_probs)\n",
    "for m in cm_dict:\n",
    "    print(m, cm_dict[m])\n",
    "cm = np.asarray(cm_dict['Confusion Matrix'])\n",
    "plot_confusion_matrix(cm, ['fail','pass'], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
